server.port=10001

#kafka对应的地址(消费者配)
spring.cloud.stream.kafka.binder.brokers= 192.168.11.133:9092
#kafka的zookeeper对应的地址（消费者和生产者都要配);注意：此配置在2.0 release开始没用了，详细如下：
#Just to close this out; the upcoming 2.0 release has no dependencies on zookeeper at all. Even though the bindings have used the pure java client for a long time now, we still needed to go via Zookeeper to provision topics.
#There is now a pure Java AdminClient (it was added in 0.11 but was not fully functional - for the binder's needs - until 1.0.0).
#参看连接：https://github.com/spring-cloud/spring-cloud-stream-binder-kafka/issues/37
#spring.cloud.stream.kafka.binder.zkNodes= 192.168.11.133:2181

# -----------------消费者--------------------
#消费者配置：监听kafka的topic
spring.cloud.stream.bindings.input.destination=personfile-event-snap
#消费者分组
spring.cloud.stream.bindings.input.group=test-group
#接收原始消息
spring.cloud.stream.bindings.input.consumer.headerMode = raw
# -----------------消费者--------------------

#------------------生产者--------------------
#生产者配置
spring.cloud.instance-count=1
spring.cloud.instance-index=0
spring.cloud.stream.kafka.binder.auto-add-partitions=true
spring.cloud.stream.kafka.binder.auto-create-topics=true
spring.cloud.stream.kafka.binder.min-partition-count=1

spring.cloud.stream.bindings.output.destination= personfile-event-snap
#spring.cloud.stream.bindings.input3.content-type=text/plain
spring.cloud.stream.bindings.output.content-type=application/json
spring.cloud.stream.bindings.output.producer.partitionCount=1
spring.cloud.stream.bindings.output.producer.headerMode = raw
# ------------------生产者--------------------